---
layout: splash 
permalink: /Research/
title: "Research"
author_profile: false
classes: wide
---

<br>
<span style="font-size: 30px; font-weight: bold;">Research</span>
<br>
<br>
<span style="font-size: 20px; font-weight: bold;">Peer-reviewed Articles</span>

- Li, Zhuofang, **Jian Cao**, Nicholas Adams-Cohen, and R. Michael Alvarez. 2023. "The Effect of Misinformation Intervention: Evidence from Trump's Tweets and the 2020 Election." _Multidisciplinary International Symposium on Disinformation in Open Online Media 2023 Proceedings_. doi: [10.1007/978-3-031-47896-3\_7](https://doi.org/10.1007/978-3-031-47896-3_7).
- **Cao, Jian**, Seo-young Silvia Kim, and R. Michael Alvarez. 2022. "Bayesian Analysis of State Voter Registration Database Integrity." _Statistics, Politics and Policy_. doi: [10.1515/spp-2021-0016](https://doi.org/10.1515/spp-2021-0016).
- **Cao, Jian**, Christina M. Ramirez, and R. Michael Alvarez. 2021. "The politics of vaccine hesitancy in the United States." _Social Science Quarterly_. doi: [10.1111/ssqu.13106](https://doi.org/10.1111/ssqu.13106).
- Alvarez, R. Michael, **Jian Cao**, and Yimeng Li. 2021. "Voting Experiences, Perceptions of Fraud, and Voter Confidence." _Social Science Quarterly_. doi: [10.1111/ssqu.12940](https://doi.org/10.1111/ssqu.12940).
- Srikanth, Maya, Anqi Liu, Nicholas Adams-Cohen, **Jian Cao**, R. Michael Alvarez, and Anima Anandkumar. 2021. "Dynamic Social Media Monitoring for Fast-Evolving Online Discussions." _Knowledge Discovery and Data Mining 2021 Proceedings_. doi: [10.1145/3447548.3467171](https://doi.org/10.1145/3447548.3467171).
- **Cao, Jian**, Nicholas Adams-Cohen, and R. Michael Alvarez. 2021. "Reliable and Efficient Long-Term Social Media Monitoring." _Journal of Computer and Communications_. doi: [10.4236/jcc.2021.910006](https://doi.org/10.4236/jcc.2021.910006).

<br>
<span style="font-size: 20px; font-weight: bold;">Working Papers</span>

> **Multiple Imputation for Large Multi-Scale Data With Linear Constraints.** _(with Paul Beaumont)_
>
> *Abstract*: Current multiple imputation methods perform poorly on large and complicated Multscale data sets such as the U.S. Bureau of Labor Statistics Quarterly Census of Employment and Wage which can have as many as 1.5 billion observations aggregated along three different scales (industry structure, geographic levels and time) and is often heavily suppressed. In this paper we present a new method that is both efficient and accurate for handling the missing and/or suppressed value problem for large multiscale data sets. Our method incor- porates three innovations. First, we improve the accuracy of the fastest multiple imputation method, bootstrapping based expectation maximization algorithm, by incorporating a mul- tiscale updating step which uses the information from the singular covariance matrix to take the multiscale structure into account and to simulate more accurate imputations. Second, we add a quasi-Monte Carlo technique to accelerate convergence speed. Third, we develop a sequential parallel method which can detect the structure and pattern of suppressed and missing observations in large data sets, and partition the data into independent small data sets automatically. We demonstrate that the resulting Parallel Sequential Multiscale Boot- strapping Expectation Maximization Multiple Imputation method is accurate, fast, and can be applied to large data sets with complicated multiscale structures.

> **Dynamic Synthetic Controls: Accounting for Varying Speeds in Comparative Case Studies.** _(with Thomas Chadefaux)_
>
> *Abstract*: Synthetic controls are widely used to estimate the causal effect of a treatment. However, they do not account for the different speeds at which units respond to changes. Reactions may be inelastic or “sticky” and thus slower due to varying regulatory, institutional, or political environments. We show that these different reaction speeds can lead to biased estimates of causal effects. We therefore introduce a dynamic synthetic control approach that accommodates varying speeds in time series, resulting in improved synthetic control estimates. We apply our method to re-estimate the effects of terrorism on income (Abadie and Gardeazabal 2003), tobacco laws on consumption (Abadie, Diamond, and Hainmueller 2010), and German reunification on GDP (Abadie, Diamond, and Hainmueller 2015). We also assess the method’s performance using Monte-Carlo simulations. We find that it reduces errors in the estimates of true treatment effects by up to 70% compared to traditional synthetic controls, improving our ability to make robust inferences. An open-source R package, dsc, is made available for easy implementation.

> **Ballot Rejections and Ballot Curing in Washington State.** _(with Canyon Foot, Jay Lee, R. Michael Alvarez, Paul Manson, and Paul Gronke)_
>
> *Abstract*: November 2020 was the first time in US history that a plurality of voters cast absentee or mail ballots. The dramatic rise of mail voting in response to the COVID-19 pandemic has led to increased attention on the potential benefits and limitations of conducting elections by mail. One of the main drawbacks to vote-by-mail policies is that states usually reject a much larger percentage of mail ballots than they do ballots cast in-person. This paper uses 27 ballot ``matchback'' files from the state of Washington to examine, for the first time, the patterns in a state's challenged and cured ballots. We find that younger voters, voters of color, inexperienced voters, and male voters all have substantially elevated rates of ballot rejections. These patterns are driven by disparities in signature-based ballot challenges, rather than differences in rates of ballot curing or any other part of the process. Additionally, we examine the amount of time between ballot challenges and ballot cures, geographic variation in rejection rates, and discuss potential policy interventions to reduce disparities and lower rejection rates overall.
 

<br>
<span style="font-size: 20px; font-weight: bold;">Work in Progress</span>

- "Clustering Historical Matrices of Dependent and Independent Variables as Unobserved Effects in Dynamic Panel Data Modeling."  
  _(with Thomas Chadefaux)_
- "Enhancing Regression Analysis through Self-Aligned DTW-Derived Speed Profiles in Time Series Data."  
  _(with Thomas Chadefaux)_
- "The Parallel Quasi-Monte Carlo Bayesian Multi-Scale Multiple Imputation Method."  
  _(with Paul Beaumont)_
- "Mailing It In: Voter Confidence in Vote-By-Mail In the 2020 Presidential Election."  
  _(with R. Michael Alvarez and Seo-young Silvia Kim)_


<br>
<span style="font-size: 20px; font-weight: bold;">Research Experience</span>

> **Trinity College Dublin**  
> _Research Fellow_ (_January 2022 – Present_)  
> _Project_: Patterns of Conflict Emergence
> - Identify patterns in the pre-conflict actions using data on conflict events and in their perceptions using data from financial markets, news articles, and diplomatic documents.
> - Evaluate the utility of these patterns to improve forecasts of conflict with both historical and live out-of-sample predictions.
> - Summarize the core features of dangerous patterns into motifs that can help build new theories of conflict emergence and escalation.

> **California Institute of Technology**  
> _Visitor_ (_January 2022 – Present_)  
> _Postdoctoral Scholar in Data Science and Election Integrity_ (_July 2019 – December 2021_)  
> _Project_: Election Auditing
> - Developed probabilistic matching and Bayesian multivariate models using GCP for large election database auditing in California and Florida.
> - Implemented entity resolution and anomaly detection on daily snapshots of voter registration databases that contain more than 20 million records and detected 10x more true anomalies than the existing methods did.
>   
> _Project_: Twitter Monitoring
> - Developed serverless architectures using GCP, AWS, and Oracle for long-term Twitter monitoring. They ingest, process, and store more than 4.5 billion tweets (30 TB in size) related to COVID-19, primary/general elections, and protests.
> - Work closely with the Computer Science team and implemented topic, spatial, network, and sentiment analyses on the collected tweets and identified COVID-19 misinformation and voting issues in the 2020 Election cycle.

> **Florida State University**  
> _Senior Researcher_ (_August 2018 – June 2019_)  
> _Project_: Large Missing Data Multiple Imputation
> - Developed the fastest and most accurate Bayesian inference method for missing data multiple imputation.
> - Developed a parallel-sequential imputation method that can impute large multi-scale data sets with 1.5 billion observations (500 GB in size).
>   
> _Project_: Economic Impact Modeling
> - Analyzed the economic impact of Florida's housing and small business policies.
> - Developed a NETS-based impact analysis tool that has 1000 times finer resolution than the existing methods.
